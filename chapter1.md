# 第1章 为什么选择Apache Flink
> 刘新春
> 2016年12月12日

*当结论与证据相吻合时，我们能够更好的理解事物；当按事物运行规律分析问题时，我们能够最有效的完成工作。*

现实生活中，我们有很多系统需要掌握--运动中的汽车发送GPS信号、金融交易、人们使用智能手机时两个发射塔之间交换信号、网络流量、机器日志以及工业传感器和可穿戴式设备产生的测量信息--这些都可以作为一个连续的事件流。如果你有能力有效的分析大规模数据流，那么你能更好、更快的理解这些系统。总之，数据流更适合表达我们生活的方式。

因此，如果我们想以流的方式收集事件，那么很自然的，我们也会以流的方式处理数据。但到现在为止，还没有一种标准的处理方法。流并不是一个全新的概念，之前它一直被认为是一种专门的、往往具有挑战性的方法。相反，企业的数据设备通常假设数据是有开始和结束的有限集合，并在某一点上变完整。这样做的主要原因是这种假设使得建立存储和处理系统更加容易，但在许多方面这种处理方式并不适合表达我们的实际生活。

有一种以流的方式处理数据的方式，但这很难做好。现在，随着各行各业的人们在更大规模的数据上开展工作，挑战变得更大。大规模分布式系统的物理特性使得严格的一致性和事件顺序的保序性是有一定限制的。但是，随着我们方法和技术的革新，我们可以尽量降低这些限制对我们业务和经营目标的影响。

这正是Apache Flink涉及的领域。Flink是由开源社区开发的一套开源软件，它使用同一套技术，不仅可以用来处理大规模流式数据，也可以用来处理批数据。

它的设计克服了其他方法在处理流式数据时有效性和易用性方面的妥协。

在本书中，我们将调研使用数据流的潜在优势，一遍您能够确定基于流的处理方式是否适合您特定的业务目标。一些流式数据的来源以及在一些情况下，这种处理方式的有效性可能会使您吃惊。此外，这本书将帮助你更好的理解Flink的技术，以及它怎么解决流式处理面临的挑战。

在本章中，我们通过分析数据流和大规模处理数据流是面临的挑战来探讨人们想要实现的什么目标。我们也会向你介绍Flink，带你初步看一下人们在实际生产中是怎么使用它的。

## 不做好数据流的后果

哪些人需要处理流式数据？给人的第一印象是与传感器测量、金融交易相关的人以及一些其他流式处理有用的领域。但是，数据流的来源更加广泛，远不止这些：两个比较熟悉的例子是网站上的点击流能够反映用户的行为和你的数据中心的机器日志。事实上，流式数据的来源是普遍存在的--只是来自连续事件的数据与以批的方式处理数据之间存在一个断层。但现在，随着大规模流式数据处理技术的发展，这一状况正在改变。

然而，进行大规模流式数据处理仍然是一个历史性的挑战，那为何还要不厌其烦的去做，而且还要做好呢？在我们看什么有了新的改变之前--新的架构和新兴的支持数据流处理的技术--让我们先看看不做好数据流的后果吧。

## 零售营销

在现代零售业中，销售往往通过网站上的一个点击来完成，而这些数据可能大规模的非均匀的持续产生。使用旧有的技术处理如此大规模的数据十分困难。即使使用批处理系统来处理这些数据流也面临挑战--结果可能是庞大而复杂的数据流。另外，结果可能丢数据、存在延迟、或是非汇聚的结果。这在商业领域怎么能容忍呢？

想象一下，你正在向你的CEO（首席执行官）报告过去一个季度的销售数据。你并不想比这更晚些时候报告，因为那样的话你的报告可能基于不准确的数据得出。如果你处理不好点击流数据，你可能不能准确统计网站的流量--这意味着你可能为广告位付费不够精确，销售数据不够理想。

航空客运服务在处理大量数据时可能面临类似的挑战，这些数据来自多个不同的数据源，需要需要快速、准确的协调处理。例如：当乘客预订时，预订信息、行李处理信息、以及付费信息必须更新。在如此大的规模上，除非有强大的流式数据处理技术，你很难跟上处理需求。当前，四分之三的主要航空服务中断可以直接归因于大规模实时数据处理问题。

当然，许多相关的问题--例如不重复预订旅店里相同的房间或是演唱会同一张门票问题--使用传统数据库可以有效的解决，但往往需要花费更高的成本和人力。随着数据规模的不断增长，成本可能飞涨，并且对许多情况来说，数据库的响应时间太慢了。因缺乏灵活性或使用一个大型复杂、不断变化的系统，发展速度可能受到影响。基本上，在大型系统中，当时某个事件发生时能够立刻响应且保持一致性和强大的承载能力是非常困难的。

幸运的是，现代流处理系统可以以一种大规模、及时且成本更少的全新处理方式帮助我们解决这些问题。流式处理也被用来解决一些新问题，例如：通过构建实时推荐系统，能够知道人们现在正在购买什么产品，以及他们还想要购买什么产品。这并不意味着流处理系统可以取代数据库--远非这些；相反，它们可以在某些情况下，解决数据库不适合处理的问题。这也可以使数据库从处理当前本地业务状态的工作中解放出来。这一转变将在第2章我们讨论流优先架构时作深入解释。

## 物联网

在物联网（IoT）领域中流式数据十分普遍，使数据以很低的延迟进行传递和处理并能够保证互数据分析的正确性，往往是至关重要的。各种类型设备上的传感器需要频发的测量数据，然后以流的方式传递到数据中心供应用进行实时或类实时处理，进行更新仪表盘，运行机器学习模型，产生告警以及为很多不同的服务提供反馈。

交通运输业是数据流处理的另一个重要例子。例如，国家列车系统依赖传感器数据从铁轨传导到列车，再由列车传导到沿线的传感器中及沿线的传感器进行控制；另外，报告信息也会回传到控制中心。测量数据包括火车的速度、位置，外加周围铁轨的信息。如果流式数据不能正确处理，则调整和告警信息不能及时发出来判断危险情况，避免事故发生。

交通运输业另一重要的例子是“智能”或者联网车辆，这些车辆被设计成可以通过移动互联网向制造商传输数据。在一些国家中（如，北欧国家、法国、英国，并开始在美国），联网车辆甚至向保险公司提供信息，在赛车时，联网车辆通过无线射频链向修理加油站发送信息供分析。一些智能手机应用也提供由数百万驾驶员共享的实时交通数据更新，如图1-1所示。


IOT也正影响着公用事业公司。公用事业公司开始应用智能电表，智能电表周期性的（如，每隔15分钟）发送使用更新，代替旧有的电表，这些旧电表每月才人工读取一次。在某些情况下，公用事业公司尝试每隔30秒测量一次数据。智能电表的这些变化产生了大量流式数据，潜在的收益也非常巨大。优点包括使用机器学习模型来探测由设备异常或能源盗窃行为造成的异常用电。如果没有有效的以高吞吐、低延迟的方式传递和准确处理流式数据，要达成这些目标是不可能的。

如果数据流做的不好，一些IOT的其他项目也难以为继。一些大型设备如风力涡轮机，制造装备，或钻井平台的水泵--这些都需要通过对传感器测量信息进行分析来提供故障报警。流分析如果做不好带来某些延迟，可能要付出高昂的代价，甚至灾难性的后果。

## 电信业

电信业是IOT领域的一个特例，基于各种不同的目的，跨不同区域的流式事件数据得到了广泛应用。如果一家电信公司不能处理好流式数据，就不能预先设定将激增流量路由到备用基站上或是对超负荷使用情况作出快速响应。数据流异常检测在电信领域非常重要--如探测掉线或设备异常。

## 银行和金融部门

如果不做好流式处理，所带来的潜在问题在银行和金融部门将更加突出。一家零售银行不希望用户交易被延迟或者记错账，否则会导致账户收支错误。老是术语“银行家时间”是指一家银行在下午早些时候关闭，冻结交易以便在第二天正常业务开始前能够做一个准确统计。那种批处理的模式早已远去。当天的交易和报告必须快速准确的给出；一些新的银行甚至在任何时候、任何地点提供即时、实时推送通知和移动银行业务。在全球经济中，能够满足24小时的商业周期需求，变得原来越重要。

如果一个金融机构不能从用户活动数据中通过敏感检测实时探测出异常行为会发生什么？信用卡交易欺诈检测需要及时监控并响应。能够检测出如网络钓鱼攻击等不寻常的登陆模式，可以将实时检测减轻的损失转化为巨大的节省。

*在很多情况下，只要准确、高效，数据的时间价值使得低延时或实时流处理充满期待。*

## 连续事件数据处理的目标

能够以非常低的延迟处理数据并不是有效进行流式处理的唯一优点。流式处理不仅期望能够高吞吐、低延时，而且能够有能力应对任务中断。一个伟大的流技术应该能够在任务失败后进行恢复并保证产生正确的结果；换句话说，要有保证数据处理exactly-once的容错机制。

此外，能够达到这一水平的容错方法在错误发生时应该不会占用太多的开销成本。具有识别会话的能力，而不是通过一个固定的处理间隔划分会话以及具有按正确顺序处理事务的能力是十分有用的。另外，能够被开发者容易使用，包括写代码和修复错误，对一个系统来说也是十分重要的，同时，它要易于维护。另外，根据事件在现实事件中发生的时间产生正确的结果对系统来说同样重要--例如，有能力处理到达乱序的事件流（一个不行的现实），能够确定性地替换流（例如，为了审计或调试）。

## 流处理技术的发展

数据连续产生和数据以有限集批处理的方式消费数据之间的脱节，将管理这种脱节的复杂性转移到系统的用户身上：需要使用和管理基础设备的应用开发者和DevOps团队。


为了管理脱节，许多用户已经开发了他们自己的流处理系统。在开源领域，流式处理的先驱是Apache Storm，Storm在在进入Apache软件基金会之前是由Nathan Marz和初创公司BackType（后来被Twitter收购）的一个团队开发负责开发。Storm使很低的延迟进行流式处理成为可能，但是这种实时处理做了妥协：高吞吐难以实现，同时Storm并没有提供通常所需要的正确性等级。换句话说，在维持正确性状态方面，它并没有exactly-once保证，即使Storm是可以提供的保障也需要很大的开销。

=============================================================

Lambda架构概述：优点和局限

对能负担得起上规模的需求，驱使人转向分布式文件系统，如HDFS，和批量计算（MapReduce作业）。但是方法难以处理低延迟的情况。由Apache Storm发展起来的实时流处理技术可以帮助解决低延迟的问题，但是不是一个完整的解决方案。一方面，Storm并不使用exactly-once处理保证状态一致性，另一方面，Storm并没有按事件时间处理的能力。

由混合这些方法提供的一种混合数据分析视图提供了一种应对这些挑战的方法。这种混合称为Lambda架构，该架构通过MapReduce批处理提供有延迟的但是准确的结果，通过Storm的处理提供一个当前时刻初步的结果视图。

Lambda架构在构建大数据应用时是一个十分有用的框架，但这远远不够。例如，一个基于MapReduce和HDFS的Lambda系统，有一个数小时的时间窗口，当失败是就会造成结果的不正确。Lambda需要对相同的业务逻辑使用不同的编程APIs进行两次编码：一次是针对批处理系统，而另一次是针对流处理系统。这导致相同的业务逻辑需要两种代码库，但是有不同种类的bugs。在现实中，这将很难维护。

============================================================

*为了计算某些依赖于多个流式事件的值，有必要保存多个事件的数据。这些保存的数据被称为计算状态。准确处理这些状态对保证计算一致性是必不可少的。当故障或中断发生时能够准确恢复状态是容错的关键。*

当流式处理具有很高的吞吐量和很低的延迟时很难保持容错，但是对状态正确性的需求促进产生了一个较为机智的妥协：如果将连续事件中的流式数据切分成一系列很小的原子批处理任务会怎么样？如果这些批被切分的足够小--即所谓的“微批”--你的计算近似为真实的流。延迟虽然不太可能达到实时，但对一些简单的应用，延迟达到秒级甚至亚秒级是有可能的。Apache Spark Streaming便采用这种方法，并运行在Spark批处理引擎上。

更重要的是，使用微批的方法，你可以保证状态一致性达到exactly-once。如果一个微批job失败了，可以重新运行一遍。这比真正的流式处理方法简单的多。Storm的一个扩展，称为Storm Trident, 在底层流式处理引擎上提供微批计算以此来保证exactly-once，但会造成明显的延迟。

然而，通过周期性微批作业的方式来模拟流式处理会导致非常脆弱的管道问题，这些管道将DevOps与应用开发的关注点混合在了一起。完成一个周期性微批job的时间与数据到来的时间之间是一种紧耦合的关系，任何的延迟可能导致结果的不一致性（也叫作错误）。这种方法潜在的问题是时间仅被创建小jobs的系统模块隐式管理。如Spark Streaming这样的框架虽然可以解决部分脆弱性，但并没有全部解决，与批相关的时间的敏感度会导致较大的延迟，用户需要较多的在应用代码中考虑性能问题。

对所需能力的妥协使人们不断尝试提高现有流处理引擎（如，开发Storm Trident是为了克服Storm的许多限制）。当现有平台存在短板时，应用开发人员就需要担负起处理这些短板引起的问题。举个例子，在微批处理并没有提供事件中自然发生的会话与处理引擎中窗口之间良好的适配，而窗口仅仅是由多个批时间（恢复间隔）构成的。由于缺乏灵活性和表达能力，开发时间变慢，算子需要花费更所的精力来正确维护。

这些这给我们带来了Apache Flink，该数据处理引擎去除了许多妥协，结合了很多可以对连续事件中的数据进行有效处理所需的功能。Flink的能力集成如下图 1-2所示。

*图1-2. Flink的一大优势是它集成了很多以前其他项目需要妥协的特征。与之相反，Apache Storm虽然提供了低延迟，但当前并没有提供高吞吐，也不支持失败时能够正确处理状态。Apache Spark Streaming的微批方法虽然达到了在保证容错的情况下很高的吞吐，但是具有较大的时间延迟，不能够将窗口与自然发生的会话进行适配，同时在表达能力上存在一些挑战。*

像Storm和Spark Streaming一样，数据流处理领域的其他新技术提供了一些有用的能力，但是很难找到一个流处理系统能够集成Flink提供的功能。例如，Apache Samza,另一较早开源的流处理引擎，只能提供at-least-once的保证和低级别的API。类似的，Apache Apex提供了一些Flink的功能，但并不完全（例如，它只有低级别编程API，不支持事件时间，并且它也不支持批量计算）。这些项目均没有形成一个与Flink社区相媲美的开源社区。


现在，让我们看一下什么是Flink，以及这个项目是怎么产生的。

## Flink之初见

Apache Flink的主页开头的口号，“Apache Flink是一个开源分布式流和批处理平台”。对很多人来说，当意识到Flink不仅提供高吞吐和exactly-once保证的流处理，同时也提供批处理时，十分震惊。你曾经不得不在这两种方法之间做出艰难的选择，但是现在，Flink使你可以使用一种技术来做两种处理。

这个Apache的顶级项目是怎么开始的呢？Flink起源于Stratosphere项目，它是由三所柏林的大学和其他欧洲大学在2010到2014年间进行的一个研究项目。该项目已经有广泛的社区基础，部分归因于在几个公共开发者会议上的分享，包括Berlin Buzzwords, NoSQL Matters in Cologne，等。这一强大的社区基础是其适合进入Apache软件基金会孵化的一个重要原因。
